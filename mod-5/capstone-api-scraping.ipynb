{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Recap: APIs and Webscraping\n",
    "\n",
    "1. Twint for tweets: https://pypi.org/project/twint/\n",
    "2. Spotipy for Spotify data: https://spotipy.readthedocs.io/en/2.16.1/\n",
    "3. PRAW for Reddit data\n",
    "3. Scraping XML from BoardGameGeek\n",
    "4. Scraping apartments from Craigslist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twint\n",
    "import pandas as pd\n",
    "\n",
    "import nest_asyncio # for some reason, needed to excute the api call\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = twint.Config()\n",
    "\n",
    "c.Search = \"covid\"\n",
    "c.Min_likes = 100000\n",
    "c.Count = True\n",
    "c.Limit = 100\n",
    "c.Store_csv = True\n",
    "c.Output = 'covidtweets.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twint Config attributes: https://github.com/twintproject/twint/wiki/Tweet-attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twint.run.Search(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('covidtweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spotipy\n",
    "* Documentation: https://spotipy.readthedocs.io/en/2.16.1/\n",
    "* Spotify's API: https://developer.spotify.com/dashboard/applications\n",
    "* Additional Spotify datasets: https://research.atspotify.com/datasets/\n",
    "\n",
    "Don't forget to store your credentials!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "sp = spotipy.Spotify(client_credentials_manager=SpotifyClientCredentials(config.spotify['client_id'], \n",
    "                                                                         config.spotify['client_secret']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists = sp.user_playlists('11138449814')['items']\n",
    "playlist_ids = [p['id'] for p in playlists]\n",
    "sp.playlist_tracks(playlist_ids[0])['items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spotipy_search(artist, track):\n",
    "    query = f'artist: {artist} track: {track}'\n",
    "    return sp.search(q=query, limit=3)['tracks']['items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotipy_search('dua lipa', 'levitating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.search(q='genre: pop', limit=10)['tracks']['items']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit\n",
    "\n",
    "https://praw.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id=config.reddit['client_id'],\n",
    "    client_secret=config.reddit['client_secret'],\n",
    "    username=config.reddit['username'],\n",
    "    password=config.reddit['password'],\n",
    "    user_agent='test'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for submission in reddit.subreddit(\"learnpython\").hot(limit=10):\n",
    "    print(submission.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(reddit.subreddit(\"punpatrol\").hot(limit=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://praw.readthedocs.io/en/latest/code_overview/models/submission.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(sub.id, sub.title, sub.url, sub.score) for sub in reddit.subreddit(\"news\").hot(limit=20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data, columns=['id', 'title', 'url', 'score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webscraping Boardgames\n",
    "\n",
    "(And dealing with XML formats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://boardgamegeek.com/xmlapi2/thing?id=3&type=boardgame'\n",
    "req = requests.get(url).content\n",
    "soup = BeautifulSoup(req, 'xml')\n",
    "games = soup.find_all('item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = games[0].find_all('name')\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names[0]['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games[0].find_all('name')[0]['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = list(filter(lambda n: n['type'] == \"primary\", names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name[0]['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games[0].find('description').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games[0].find('description').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Craigslist\n",
    "\n",
    "https://newyork.craigslist.org/search/aap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.findAll('li', {'class':\"result-row\"})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "url = 'https://newyork.craigslist.org/search/hhh?'\n",
    "soup = BeautifulSoup(requests.get(url).text)\n",
    "\n",
    "# getting each apartment's html as an element in a list\n",
    "\n",
    "apartments =  soup.findAll('li', {'class':\"result-row\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apartments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [a.find('a', {'class': 'result-title hdrlnk'}).text for a in apartments]\n",
    "prices = [a.find('span', {'class': 'result-price'}).text for a in apartments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting attributes via list comprehension\n",
    "hoods = []\n",
    "for a in apartments:\n",
    "    result = a.find('span', {'class': 'result-hood'})\n",
    "    if result == None:\n",
    "        hoods.append(None)\n",
    "    else:\n",
    "        hoods.append(result.text)\n",
    "\n",
    "# for 'hoods', some are NoneType\n",
    "\n",
    "# putting it in a dataframe:\n",
    "\n",
    "df = pd.DataFrame(columns = ['titles', 'prices', 'hoods'])\n",
    "df['titles'] = titles\n",
    "df['prices'] = prices\n",
    "df['hoods'] = hoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Things to Explore\n",
    "\n",
    "* BeautifulSoup not finding the exact info you're trying to scrape? Try **Selenium** \n",
    "    * https://www.scrapingbee.com/blog/selenium-python/\n",
    "    \n",
    "* ScraPy is another library (newer) used for scraping\n",
    "    * https://scrapy.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
